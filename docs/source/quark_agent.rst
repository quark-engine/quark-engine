Quark Agent
===========

Introducing Quark's new member, the Quark Agent, the second AI assistant in the Quark team. This agent lets users get Quark reports using natural language, eliminating the need for terminal commands and making the analysis simple and user-friendly.

The Quark Agent integrates with LangChain, using OpenAI's large language model to act as a bridge between the natural language and the Quark APIs. LangChain defines the Quark APIs as tools that large language models can understand and use. This means users can run any Quark analysis using natural language by simply adding new tools as needed.

Showcase: Generate Summary Report with Quark Agent
--------------------------------------------------

Here's an example of using the Quark Agent. This agent can currently analyze `ovaa.apk <https://github.com/oversecured/ovaa>`__ and generate a :ref:`summary report <summary-report>`. See the details below.

Quick Start
~~~~~~~~~~~

1. Install the Quark Agent:

   .. code-block:: shell

      pip install quark-engine[QuarkAgent]

2. Prepare the rule and the sample:

   .. code-block:: shell

      git clone https://github.com/quark-engine/quark-script
      cd quark-script

3. Add your OpenAI API key to the environment:

   .. code-block:: python

      export OPENAI_API_KEY='your-api-key-here'

4. Run the Quark Agent:

   .. code-block:: shell

      quark-agent

5. Result:

.. image:: https://github.com/user-attachments/assets/46407664-de0d-4849-8995-642ff636d71e


Decode the Process
~~~~~~~~~~~~~~~~~~

Here, we explain what happens after running the Quark Agent.

Before processing user prompts, the Quark Agent uses a preset prompt to ensure the ``gpt-4o-mini`` model knows the format of a summary report.

.. code:: TEXT

    Preset Prompt:

    When prompted to provide a summary report, follow these rules and the summary report example:

      1. Print a newline character first to prevent formatting issues.
      2. Change "<RISK_LEVEL>" in "WARNING: <RISK_LEVEL>" to the risk level with the first letter of each word capitalized.
      3. Change "<TOTAL_SCORE>" in "Total Score: <TOTAL_SCORE>" to the total score, expressed as a decimal numeral.
      4. Without using a code block, place the output of the tool, getSummaryReportTable, in the line directly after "Total Score: <TOTAL_SCORE>".

    The Summary Report Example:

    [!] WARNING: <RISK_LEVEL>
    [*] Total Score: <TOTAL_SCORE>
    +--------------------------------+-----------------------------+------------+-------+--------+  
    | Filename                       | Rule                        | Confidence | Score | Weight |  
    +--------------------------------+-----------------------------+------------+-------+--------+  
    | constructCryptoGraphicKey.json | Construct cryptographic key | 100%       | 1     | 1.0    |  
    +--------------------------------+-----------------------------+------------+-------+--------+ 

    Ensure you adhere to these rules and the example when providing a summary report.

The preset prompt is hard-coded into the Quark Agent. When the Quark Agent connects to the ``gpt-4o-mini`` model, it automatically uses the preset prompt to initialize the model. Hence, we don't need to pass this prompt manually.

Then, by passing the following prompt manually, we ask the Quark Agent to analyze the `ovaa.apk <https://github.com/oversecured/ovaa>`__ sample and generate a summary report. 

.. code:: TEXT

   1st Prompt: Analyze the sample “ovaa.apk” using Quark and the rule “constructCryptoGraphicKey.json.”
               After the analysis, print the summary report.

Used Quark APIs/Tools that LLM used: ``initRuleObject``, ``initQuarkObject``, ``runQuarkAnalysis``, ``getSummaryReportTable``, ``getAnalysisResultRisk``, and ``getAnalysisResultScore``

To highlight the analysis result, we ask the Quark Agent to colorize the summary report.

.. code:: TEXT

   2nd Prompt: Colorize "[!]" in yellow, "[*]" in cyan, the "Rule" column and its data in green,
               the "Confidence" column and its data in yellow, and the "Weight" column and its data in red.

Used Quark APIs/Tools that LLM used: ``colorizeInYellow``, ``colorizeInCyan``, ``colorizeInGreen``, and ``colorizeInRed``



All APIs above are treated as tools within LangChain, enabling them to be invoked through the ``gpt-4o-min`` model to analyze the `ovaa.apk <https://github.com/oversecured/ovaa>`__ sample and generate a colorized summary report.

.. image:: https://github.com/user-attachments/assets/fce1e4d4-ca6b-4b54-a2a3-1b84f039a621

.. note::
   1. The summary report is generated by OpenAI's GPT model and is not always correct.
   2. Since LangChain currently does not support passing Python instances between tools, we temporarily use global variables to pass parameters between tools.
   3. Place the rules and samples in the working directory; the LLM will automatically find the files with matching names.
   4. The scores and weights in the summary report are currently set based on our experience. In the future, Quark Agent will determine these values to provide a more accurate risk assessment. Please stay tuned!
